{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "import joblib as jb\n",
    "from collections import defaultdict\n",
    "from itertools import groupby\n",
    "from math import sqrt, atan2\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from scipy.signal import savgol_filter\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine semi controlled CSI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_list = os.listdir(os.path.abspath('./preprocess/semi'))\n",
    "check_list.sort()\n",
    "first_names = [re.match(r'([^_]+)_', filename).group(1) for filename in check_list]\n",
    "\n",
    "# Get unique first names\n",
    "unique_first_names = set(first_names)\n",
    "unique_first_names\n",
    "\n",
    "dir_list = os.path.abspath('./preprocess/semi')\n",
    "save= os.path.abspath('./input_combine/semi')\n",
    "list_dir = os.listdir(dir_list)\n",
    "list_dir.sort()\n",
    "name=[] \n",
    "for k in unique_first_names: \n",
    "    os.makedirs(f'{save}/{k}', exist_ok=True)\n",
    "    for i in list_dir:\n",
    "        temp = i.split(\"_\")\n",
    "        name.append(temp[0])\n",
    "    name_unique= np.unique(name)\n",
    "    combine_list=[]\n",
    "    for i in list_dir:\n",
    "        if k in i:\n",
    "            complete_path = f'{dir_list}/{i}'\n",
    "            with open(complete_path, 'rb') as f:\n",
    "                result = pickle.load(f)\n",
    "            # column=result.shape[1]\n",
    "            # print(column)\n",
    "            len= result.shape[0]\n",
    "            len=int(abs(0.03*len))\n",
    "            # print(result.shape)\n",
    "            combine_list.append(result)\n",
    "        else:\n",
    "            pass\n",
    "    df = pd.concat(combine_list, axis=0)\n",
    "    # df= df.drop(columns=['timestamp'], axis=1)\n",
    "    df= df.reset_index(drop=True)\n",
    "    print(df.shape)\n",
    "    if 'headlabel' in df.columns:\n",
    "        print('here')\n",
    "        group = df.groupby('headlabel')\n",
    "        label_name = list(group.groups.keys())\n",
    "        for i in label_name:\n",
    "            df_temp = group.get_group(i)\n",
    "            df_temp=df_temp.reset_index(drop=True)\n",
    "            df_temp = df_temp.iloc[0:,0:114]\n",
    "            complete_path= f'{save}/{k}/{i}'\n",
    "            with open(complete_path, 'wb') as f:\n",
    "                pickle.dump(df_temp,f )\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine in-the-wild CSI files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_list = os.listdir(os.path.abspath('./preprocess/wild'))\n",
    "check_list.sort()\n",
    "first_names = [re.match(r'([^_]+)_', filename).group(1) for filename in check_list]\n",
    "\n",
    "# Get unique first names\n",
    "unique_first_names = set(first_names)\n",
    "unique_first_names\n",
    "\n",
    "dir_list = os.path.abspath('./preprocess/wild')\n",
    "save= os.path.abspath('./input_combine/wild')\n",
    "list_dir = os.listdir(dir_list)\n",
    "list_dir.sort()\n",
    "name=[] \n",
    "for k in unique_first_names: \n",
    "    os.makedirs(f'{save}/{k}', exist_ok=True)\n",
    "    for i in list_dir:\n",
    "        temp = i.split(\"_\")\n",
    "        name.append(temp[0])\n",
    "    name_unique= np.unique(name)\n",
    "    combine_list=[]\n",
    "    for i in list_dir:\n",
    "        if k in i:\n",
    "            complete_path = f'{dir_list}/{i}'\n",
    "            with open(complete_path, 'rb') as f:\n",
    "                result = pickle.load(f)\n",
    "            # column=result.shape[1]\n",
    "            # print(column)\n",
    "            len= result.shape[0]\n",
    "            len=int(abs(0.03*len))\n",
    "            # print(result.shape)\n",
    "            combine_list.append(result)\n",
    "        else:\n",
    "            pass\n",
    "    df = pd.concat(combine_list, axis=0)\n",
    "    # df= df.drop(columns=['timestamp'], axis=1)\n",
    "    df= df.reset_index(drop=True)\n",
    "    print(df.shape)\n",
    "    if 'headlabel' in df.columns:\n",
    "        print('here')\n",
    "        group = df.groupby('headlabel')\n",
    "        label_name = list(group.groups.keys())\n",
    "        for i in label_name:\n",
    "            df_temp = group.get_group(i)\n",
    "            df_temp=df_temp.reset_index(drop=True)\n",
    "            df_temp = df_temp.iloc[0:,0:114]\n",
    "            complete_path= f'{save}/{k}/{i}'\n",
    "            with open(complete_path, 'wb') as f:\n",
    "                pickle.dump(df_temp,f )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
