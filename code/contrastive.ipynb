{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import joblib\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "folder ='S1' # change the folder as per requirement\n",
    "feat_train_amp = pd.read_csv(os.path.abspath(f'./training_testing_data/{folder}/X_train.csv'))\n",
    "label_train_amp=pd.read_csv(os.path.abspath(f'./training_testing_data/{folder}/y_train.csv'))\n",
    "feat_test_amp = pd.read_csv(os.path.abspath(f'./training_testing_data/{folder}/X_test.csv'))\n",
    "label_test_amp = pd.read_csv(os.path.abspath(f'./training_testing_data/{folder}/y_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess step \n",
    "df = pd.concat([feat_train_amp, label_train_amp], axis=1)\n",
    "feature_columns=[]\n",
    "for i in range(114):\n",
    "    feature_columns.append(i)\n",
    "input=np.array(df.iloc[:,feature_columns])\n",
    "target=np.array(df['headlabel'])\n",
    "\n",
    "input=np.abs(input)\n",
    "\n",
    "input=SelectKBest(chi2, k=96).fit_transform(input, target)\n",
    "\n",
    "headlabels=np.unique(target)\n",
    "\n",
    "dfs={}\n",
    "\n",
    "for i in headlabels:\n",
    "    dfs[i]=[]\n",
    "for i in range(target.shape[0]):\n",
    "    dfs[target[i]].append(input[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13760, 96)\n",
      "(4512, 96)\n",
      "(8896, 96)\n",
      "(1120, 96)\n",
      "(1632, 96)\n",
      "(4800, 96)\n",
      "(2272, 96)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "X_train=[0]*9\n",
    "X_test=[0]*9\n",
    "Y_train=[0]*9\n",
    "Y_test=[0]*9\n",
    "\n",
    "for i in range(7):\n",
    "    random.shuffle(dfs[headlabels[i]])\n",
    "    rows_to_rem=0-(len(dfs[headlabels[i]])%32)\n",
    "    if(rows_to_rem!=0):\n",
    "        dfs[headlabels[i]]=dfs[headlabels[i]][:rows_to_rem]\n",
    "    rows=int(len(dfs[headlabels[i]])/32)\n",
    "    dfs[headlabels[i]]=np.array(dfs[headlabels[i]])\n",
    "    print(dfs[headlabels[i]].shape)\n",
    "    dfs[headlabels[i]]=dfs[headlabels[i]].reshape(rows,32,32,3)\n",
    "    X_train[i], X_test[i], Y_train[i], Y_test[i] = train_test_split(dfs[headlabels[i]], np.array([headlabels[i]]*rows), test_size=0.3, random_state=42)\n",
    "\n",
    "input=[]\n",
    "target=[]\n",
    "\n",
    "for i in range(7):\n",
    "    for j in dfs[headlabels[i]]:\n",
    "        input.append(j)\n",
    "        target.append(i)\n",
    "\n",
    "input=np.array(input)\n",
    "target=np.array(target)\n",
    "\n",
    "input_train=[]\n",
    "target_train=[]\n",
    "\n",
    "for i in range(7):\n",
    "    for j in X_train[i]:\n",
    "        input_train.append(j)\n",
    "        target_train.append(i)\n",
    "\n",
    "input_train=np.array(input_train)\n",
    "target_train=np.array(target_train)\n",
    "\n",
    "input_val=[]\n",
    "target_val=[]\n",
    "\n",
    "for i in range(7):\n",
    "    for j in X_test[i]:\n",
    "        input_val.append(j)\n",
    "        target_val.append(i)\n",
    "\n",
    "input_val=np.array(input_val)\n",
    "target_val=np.array(target_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_input_train, original_input_test, original_output_train, original_output_test = train_test_split(input, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    " \n",
    "# Split a dataset into 2 folds\n",
    "def cross_validation_split(input, target, folds):\n",
    "\tinput_split=[]\n",
    "\tinput_copy=list(input.copy())\n",
    "\ttarget_split=[]\n",
    "\ttarget_copy=list(target.copy())\n",
    "\tfold_size=int(len(input)/folds)\n",
    "\tfor i in range(folds):\n",
    "\t\tfold_input=[]\n",
    "\t\tfold_target=[]\n",
    "\t\twhile len(fold_input) < fold_size:\n",
    "\t\t\tindex = randrange(len(input_copy))\n",
    "\t\t\tfold_input.append(input_copy.pop(index))\n",
    "\t\t\tfold_target.append(target_copy.pop(index))\n",
    "\t\tinput_split.append(fold_input)\n",
    "\t\ttarget_split.append(fold_target)\n",
    "\treturn input_split, target_split\n",
    "\n",
    "seed(1)\n",
    "folds_input, folds_target = cross_validation_split(original_input_train, original_output_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "\n",
    "# Define the custom loss function\n",
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def call(self, labels, feature_vectors, sample_weight=None):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "# Add projection head to the encoder\n",
    "def add_projection_head(encoder, projection_units=128):\n",
    "    inputs = keras.Input(shape=(32, 32, 3))\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\")\n",
    "    return model\n",
    "\n",
    "# Create classifier\n",
    "def create_classifier(encoder, trainable=True, hidden_units=512, dropout_rate=0.5, learning_rate=0.001):\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=(32, 32, 3))\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(7, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Assuming folds_input and folds_target are defined and contain your data\n",
    "# For this example, we'll use dummy data\n",
    "# folds_input = [np.random.rand(100, 32, 32, 3) for _ in range(3)]\n",
    "# folds_target = [np.random.randint(0, 7, 100) for _ in range(3)]\n",
    "\n",
    "accuracies = []\n",
    "learning_rate = 0.001\n",
    "batch_size = 800\n",
    "hidden_units = 512\n",
    "projection_units = 128\n",
    "num_epochs = 100\n",
    "dropout_rate = 0.5\n",
    "temperature = 0.05\n",
    "\n",
    "for i in range(2):\n",
    "    input_train = []\n",
    "    input_val = []\n",
    "    target_train = []\n",
    "    target_val = []\n",
    "\n",
    "    for sample in range(len(folds_input[i])):\n",
    "        input_val.append(folds_input[i][sample])\n",
    "        target_val.append(folds_target[i][sample])\n",
    "\n",
    "    for j in range(2):\n",
    "        if j == i:\n",
    "            continue\n",
    "        for sample in range(len(folds_input[j])):\n",
    "            input_train.append(folds_input[j][sample])\n",
    "            target_train.append(folds_target[j][sample])\n",
    "\n",
    "    input_train = np.array(input_train)\n",
    "    input_val = np.array(input_val)\n",
    "    target_train = np.array(target_train)\n",
    "    target_val = np.array(target_val)\n",
    "\n",
    "\n",
    "    encoder = create_encoder()\n",
    "    encoder_with_projection_head = add_projection_head(encoder)\n",
    "    encoder_with_projection_head.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=SupervisedContrastiveLoss(temperature),\n",
    "        run_eagerly=True\n",
    "    )\n",
    "\n",
    "    encoder_with_projection_head.summary()\n",
    "\n",
    "    history = encoder_with_projection_head.fit(\n",
    "        x=input_train, y=target_train, batch_size=batch_size, epochs=num_epochs\n",
    "    )\n",
    "\n",
    "    classifier = create_classifier(encoder, trainable=False)\n",
    "    history = classifier.fit(x=input_train, y=target_train, batch_size=batch_size, epochs=num_epochs)\n",
    "\n",
    "    loss, accuracy = classifier.evaluate(input_val, target_val)\n",
    "    accuracies.append(round(accuracy * 100, 2))\n",
    "\n",
    "print(\"Accuracies:\", accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pred=classifier.predict(original_input_test)\n",
    "target_predict = np.argmax(target_pred, axis=1)\n",
    "print(\"Accuracy: \"+str(accuracy_score(target_predict,original_output_test)))\n",
    "print(\"F1 Score: \"+str(f1_score(target_predict,original_output_test,average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    " \n",
    "# Split a dataset into 2 folds\n",
    "def cross_validation_split(input, target, folds):\n",
    "\tinput_split=[]\n",
    "\tinput_copy=list(input.copy())\n",
    "\ttarget_split=[]\n",
    "\ttarget_copy=list(target.copy())\n",
    "\tfold_size=int(len(input)/folds)\n",
    "\tfor i in range(folds):\n",
    "\t\tfold_input=[]\n",
    "\t\tfold_target=[]\n",
    "\t\twhile len(fold_input) < fold_size:\n",
    "\t\t\tindex = randrange(len(input_copy))\n",
    "\t\t\tfold_input.append(input_copy.pop(index))\n",
    "\t\t\tfold_target.append(target_copy.pop(index))\n",
    "\t\tinput_split.append(fold_input)\n",
    "\t\ttarget_split.append(fold_target)\n",
    "\treturn input_split, target_split\n",
    "\n",
    "seed(1)\n",
    "folds_input, folds_target = cross_validation_split(original_input_train, original_output_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "\n",
    "# Define the custom loss function\n",
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def call(self, labels, feature_vectors, sample_weight=None):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "# Add projection head to the encoder\n",
    "def add_projection_head(encoder, projection_units=128):\n",
    "    inputs = keras.Input(shape=(32, 32, 3))\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\")\n",
    "    return model\n",
    "\n",
    "# Create classifier\n",
    "def create_classifier(encoder, trainable=True, hidden_units=512, dropout_rate=0.5, learning_rate=0.001):\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=(32, 32, 3))\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(7, activation=import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "\n",
    "# Define the custom loss function\n",
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def call(self, labels, feature_vectors, sample_weight=None):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "# Add projection head to the encoder\n",
    "def add_projection_head(encoder, projection_units=128):\n",
    "    inputs = keras.Input(shape=(32, 32, 3))\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\")\n",
    "    return model\n",
    "\n",
    "# Create classifier\n",
    "def create_classifier(encoder, trainable=True, hidden_units=512, dropout_rate=0.5, learning_rate=0.001):\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=(32, 32, 3))\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(7, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Assuming folds_input and folds_target are defined and contain your data\n",
    "# For this example, we'll use dummy data\n",
    "# folds_input = [np.random.rand(100, 32, 32, 3) for _ in range(3)]\n",
    "# folds_target = [np.random.randint(0, 7, 100) for _ in range(3)]\n",
    "\n",
    "accuracies = []\n",
    "learning_rate = 0.001\n",
    "batch_size = 800\n",
    "hidden_units = 512\n",
    "projection_units = 128\n",
    "num_epochs = 100\n",
    "dropout_rate = 0.5\n",
    "temperature = 0.05\n",
    "\n",
    "for i in range(2):\n",
    "    input_train = []\n",
    "    input_val = []\n",
    "    target_train = []\n",
    "    target_val = []\n",
    "\n",
    "    for sample in range(len(folds_input[i])):\n",
    "        input_val.append(folds_input[i][sample])\n",
    "        target_val.append(folds_target[i][sample])\n",
    "\n",
    "    for j in range(2):\n",
    "        if j == i:\n",
    "            continue\n",
    "        for sample in range(len(folds_input[j])):\n",
    "            input_train.append(folds_input[j][sample])\n",
    "            target_train.append(folds_target[j][sample])\n",
    "\n",
    "    input_train = np.array(input_train)\n",
    "    input_val = np.array(input_val)\n",
    "    target_train = np.array(target_train)\n",
    "    target_val = np.array(target_val)\n",
    "\n",
    "\n",
    "    encoder = create_encoder()\n",
    "    encoder_with_projection_head = add_projection_head(encoder)\n",
    "    encoder_with_projection_head.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=SupervisedContrastiveLoss(temperature),\n",
    "        run_eagerly=True\n",
    "    )\n",
    "\n",
    "    encoder_with_projection_head.summary()\n",
    "\n",
    "    history = encoder_with_projection_head.fit(\n",
    "        x=input_train, y=target_train, batch_size=batch_size, epochs=num_epochs\n",
    "    )\n",
    "\n",
    "    classifier = create_classifier(encoder, trainable=False)\n",
    "    history = classifier.fit(x=input_train, y=target_train, batch_size=batch_size, epochs=num_epochs)\n",
    "\n",
    "    loss, accuracy = classifier.evaluate(input_val, target_val)\n",
    "    accuracies.append(round(accuracy * 100, 2))\n",
    "\n",
    "print(\"Accuracies:\", accuracies)\n",
    "\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Assuming folds_input and folds_target are defined and contain your data\n",
    "# For this example, we'll use dummy data\n",
    "# folds_input = [np.random.rand(100, 32, 32, 3) for _ in range(3)]\n",
    "# folds_target = [np.random.randint(0, 7, 100) for _ in range(3)]\n",
    "\n",
    "accuracies = []\n",
    "learning_rate = 0.001\n",
    "batch_size = 800\n",
    "hidden_units = 512\n",
    "projection_units = 128\n",
    "num_epochs = 20\n",
    "dropout_rate = 0.5\n",
    "temperature = 0.05\n",
    "\n",
    "for i in range(10):\n",
    "    input_train = []\n",
    "    input_val = []\n",
    "    target_train = []\n",
    "    target_val = []\n",
    "\n",
    "    for sample in range(len(folds_input[i])):\n",
    "        input_val.append(folds_input[i][sample])\n",
    "        target_val.append(folds_target[i][sample])\n",
    "\n",
    "    for j in range(10):\n",
    "        if j == i:\n",
    "            continue\n",
    "        for sample in range(len(folds_input[j])):\n",
    "            input_train.append(folds_input[j][sample])\n",
    "            target_train.append(folds_target[j][sample])\n",
    "\n",
    "    input_train = np.array(input_train)\n",
    "    input_val = np.array(input_val)\n",
    "    target_train = np.array(target_train)\n",
    "    target_val = np.array(target_val)\n",
    "\n",
    "\n",
    "    encoder = create_encoder()\n",
    "    encoder_with_projection_head = add_projection_head(encoder)\n",
    "    encoder_with_projection_head.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=SupervisedContrastiveLoss(temperature),\n",
    "        run_eagerly=True\n",
    "    )\n",
    "\n",
    "    encoder_with_projection_head.summary()\n",
    "\n",
    "    history = encoder_with_projection_head.fit(\n",
    "        x=input_train, y=target_train, batch_size=batch_size, epochs=num_epochs\n",
    "    )\n",
    "\n",
    "    classifier = create_classifier(encoder, trainable=False)\n",
    "    history = classifier.fit(x=input_train, y=target_train, batch_size=batch_size, epochs=num_epochs)\n",
    "\n",
    "    loss, accuracy = classifier.evaluate(input_val, target_val)\n",
    "    accuracies.append(round(accuracy * 100, 2))\n",
    "\n",
    "print(\"Accuracies:\", accuracies)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
